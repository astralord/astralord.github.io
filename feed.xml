<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://astralord.github.io/</id><title>AstraBlog</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2024-01-31T21:31:14+03:00</updated> <author> <name>Aleksandr Samarin</name> <uri>https://astralord.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://astralord.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://astralord.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator> <rights> © 2024 Aleksandr Samarin </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Exploring Parallel Strategies with Jax</title><link href="https://astralord.github.io/posts/exploring-parallel-strategies-with-jax/" rel="alternate" type="text/html" title="Exploring Parallel Strategies with Jax" /><published>2024-01-27T06:00:00+03:00</published> <updated>2024-01-31T14:29:34+03:00</updated> <id>https://astralord.github.io/posts/exploring-parallel-strategies-with-jax/</id> <content src="https://astralord.github.io/posts/exploring-parallel-strategies-with-jax/" /> <author> <name>Aleksandr Samarin</name> </author> <category term="ML Engineering" /> <summary> Training large language models either like GPT, LlaMa or Mixtral requires immense computational resources. With model sizes ballooning into the billions or sometimes even trillions of parameters, specialized parallelization techniques are essential to make training feasible. In this post, we’ll explore implementing some of these scaling strategies in Jax - a Python framework designed for hig... </summary> </entry> <entry><title>Building Aligned Intelligence System. Part II. Improving Large Language Models</title><link href="https://astralord.github.io/posts/building-aligned-intelligence-systems-part-ii-applying-large-language-models/" rel="alternate" type="text/html" title="Building Aligned Intelligence System. Part II. Improving Large Language Models" /><published>2023-07-23T19:00:00+03:00</published> <updated>2024-01-28T01:08:08+03:00</updated> <id>https://astralord.github.io/posts/building-aligned-intelligence-systems-part-ii-applying-large-language-models/</id> <content src="https://astralord.github.io/posts/building-aligned-intelligence-systems-part-ii-applying-large-language-models/" /> <author> <name>Aleksandr Samarin</name> </author> <category term="Generative AI" /> <category term="Large Language Models" /> <summary> In this post we will look at different techniques for steering LLMs behaviour to get desired outcomes, starting with some basic general principles such as writing a good prompt and ending with fine-tuning and augmenting models with external knowledge. Methods discussed in this post are mainly aimed at improving LLMs reliability and ensuring the consistency and factual accuracy of their... </summary> </entry> <entry><title>Building Aligned Intelligence System. Part I: Creating GPT Assistant</title><link href="https://astralord.github.io/posts/building-aligned-intelligence-systems-part-i-creating-gpt-assistant/" rel="alternate" type="text/html" title="Building Aligned Intelligence System. Part I: Creating GPT Assistant" /><published>2023-07-03T06:00:00+03:00</published> <updated>2024-01-31T21:05:21+03:00</updated> <id>https://astralord.github.io/posts/building-aligned-intelligence-systems-part-i-creating-gpt-assistant/</id> <content src="https://astralord.github.io/posts/building-aligned-intelligence-systems-part-i-creating-gpt-assistant/" /> <author> <name>Aleksandr Samarin</name> </author> <category term="Generative AI" /> <category term="Large Language Models" /> <summary> In recent years, the field of natural language processing has witnessed a remarkable breakthrough with the advent of Large Language Models (LLMs). These models have demonstrated unprecedented performance in a wide range of language tasks, from text generation to question answering. However, the mathematical formulation of these models and the techniques used to fine-tune them for specific ta... </summary> </entry> <entry><title>Power of Diffusion Models</title><link href="https://astralord.github.io/posts/power-of-diffusion-models/" rel="alternate" type="text/html" title="Power of Diffusion Models" /><published>2022-09-25T06:00:00+03:00</published> <updated>2023-07-03T23:09:13+03:00</updated> <id>https://astralord.github.io/posts/power-of-diffusion-models/</id> <content src="https://astralord.github.io/posts/power-of-diffusion-models/" /> <author> <name>Aleksandr Samarin</name> </author> <category term="Generative AI" /> <category term="Diffusion Models" /> <summary> In 2022, insanely beautiful and original images created with generative neural networks are taking the internet by storm. This post focuses on the theory behind diffusion models that underpin the core ideas of the latest generative AI. Brace yourself, this post is math-heavy and there are a lot of formulas ahead. In 2022 ‘Théâtre D’opéra Spatial’, an artwork by Jason M. Allen with help of... </summary> </entry> <entry><title>Applying Graph Neural Networks to Kaggle Competition</title><link href="https://astralord.github.io/posts/applying-graph-neural-networks-to-kaggle-competition/" rel="alternate" type="text/html" title="Applying Graph Neural Networks to Kaggle Competition" /><published>2022-07-24T19:00:00+03:00</published> <updated>2023-07-03T23:09:13+03:00</updated> <id>https://astralord.github.io/posts/applying-graph-neural-networks-to-kaggle-competition/</id> <content src="https://astralord.github.io/posts/applying-graph-neural-networks-to-kaggle-competition/" /> <author> <name>Aleksandr Samarin</name> </author> <category term="Graph Neural Networks" /> <summary> Few months ago, Kaggle launched featured simulation competition Kore-2022. In this kind of competitions participants bots are competing against each other in an game environment, supported by Kaggle. Often there are 2 or 4 players in a game, at the end each winner/loser moves up/down according to skill rating system. Team reaching top-rating wins. Kore rules That’s how entry to Kore competiti... </summary> </entry> </feed>
